{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/pink_floyd_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'side': 1,\n",
       " 'that': 2,\n",
       " 'cat’s': 3,\n",
       " 'something': 4,\n",
       " 'i': 5,\n",
       " 'can’t': 6,\n",
       " 'explain': 7,\n",
       " 'cat': 8,\n",
       " 'you’re': 9,\n",
       " 'a': 10,\n",
       " 'the': 11,\n",
       " 'be': 12,\n",
       " 'lucifer': 13,\n",
       " 'always': 14,\n",
       " 'by': 15,\n",
       " 'your': 16,\n",
       " 'around': 17,\n",
       " 'sam': 18,\n",
       " 'siam': 19,\n",
       " 'sitting': 20,\n",
       " 'jennifer': 21,\n",
       " 'gentle': 22,\n",
       " 'witch': 23,\n",
       " 'left': 24,\n",
       " 'he’s': 25,\n",
       " 'right': 26,\n",
       " 'oh': 27,\n",
       " 'no': 28,\n",
       " 'go': 29,\n",
       " 'to': 30,\n",
       " 'sea': 31,\n",
       " 'hip': 32,\n",
       " 'ship’s': 33,\n",
       " 'somewhere': 34,\n",
       " 'anywhere': 35,\n",
       " 'at': 36,\n",
       " 'night': 37,\n",
       " 'prowling': 38,\n",
       " 'sifting': 39,\n",
       " 'sand': 40,\n",
       " 'hiding': 41,\n",
       " 'on': 42,\n",
       " 'ground': 43,\n",
       " 'he’ll': 44,\n",
       " 'found': 45,\n",
       " 'when': 46}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts([df.lyrics.iloc[1].replace('\\n',' \\n ')])\n",
    "tokenizer.word_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.lyrics.iloc[1].split('\\n')\n",
    "text = [re.sub(r'\\d+', '', i) for i in text]\n",
    "corpus = list(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lucifer Sam, siam cat',\n",
       " '',\n",
       " 'You’re the left side, he’s the right side',\n",
       " 'Always sitting by your side',\n",
       " 'Always by your side',\n",
       " 'Jennifer Gentle, you’re a witch',\n",
       " 'Oh, no!',\n",
       " 'Lucifer, go to sea',\n",
       " 'That cat’s something I can’t explain',\n",
       " 'Hiding around on the ground',\n",
       " 'Be a hip cat, be a ship’s cat',\n",
       " 'Somewhere, anywhere',\n",
       " 'At night prowling, sifting sand',\n",
       " 'He’ll be found when you’re around']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "[13, 18, 19, 8]\n",
      "--------------------------------------------------\n",
      "[13, 18]\n",
      "[13, 18, 19]\n",
      "[13, 18, 19, 8]\n",
      "--------------------------------------------------\n",
      "[]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[9, 11, 24, 1, 25, 11, 26, 1]\n",
      "--------------------------------------------------\n",
      "[9, 11]\n",
      "[9, 11, 24]\n",
      "[9, 11, 24, 1]\n",
      "[9, 11, 24, 1, 25]\n",
      "[9, 11, 24, 1, 25, 11]\n",
      "[9, 11, 24, 1, 25, 11, 26]\n",
      "[9, 11, 24, 1, 25, 11, 26, 1]\n",
      "--------------------------------------------------\n",
      "[14, 20, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[14, 20]\n",
      "[14, 20, 15]\n",
      "[14, 20, 15, 16]\n",
      "[14, 20, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[14, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[14, 15]\n",
      "[14, 15, 16]\n",
      "[14, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[21, 22, 9, 10, 23]\n",
      "--------------------------------------------------\n",
      "[21, 22]\n",
      "[21, 22, 9]\n",
      "[21, 22, 9, 10]\n",
      "[21, 22, 9, 10, 23]\n",
      "--------------------------------------------------\n",
      "[27, 28]\n",
      "--------------------------------------------------\n",
      "[27, 28]\n",
      "--------------------------------------------------\n",
      "[13, 29, 30, 31]\n",
      "--------------------------------------------------\n",
      "[13, 29]\n",
      "[13, 29, 30]\n",
      "[13, 29, 30, 31]\n",
      "--------------------------------------------------\n",
      "[2, 3, 4, 5, 6, 7]\n",
      "--------------------------------------------------\n",
      "[2, 3]\n",
      "[2, 3, 4]\n",
      "[2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[2, 3, 4, 5, 6, 7]\n",
      "--------------------------------------------------\n",
      "[41, 17, 42, 11, 43]\n",
      "--------------------------------------------------\n",
      "[41, 17]\n",
      "[41, 17, 42]\n",
      "[41, 17, 42, 11]\n",
      "[41, 17, 42, 11, 43]\n",
      "--------------------------------------------------\n",
      "[12, 10, 32, 8, 12, 10, 33, 8]\n",
      "--------------------------------------------------\n",
      "[12, 10]\n",
      "[12, 10, 32]\n",
      "[12, 10, 32, 8]\n",
      "[12, 10, 32, 8, 12]\n",
      "[12, 10, 32, 8, 12, 10]\n",
      "[12, 10, 32, 8, 12, 10, 33]\n",
      "[12, 10, 32, 8, 12, 10, 33, 8]\n",
      "--------------------------------------------------\n",
      "[34, 35]\n",
      "--------------------------------------------------\n",
      "[34, 35]\n",
      "--------------------------------------------------\n",
      "[36, 37, 38, 39, 40]\n",
      "--------------------------------------------------\n",
      "[36, 37]\n",
      "[36, 37, 38]\n",
      "[36, 37, 38, 39]\n",
      "[36, 37, 38, 39, 40]\n",
      "--------------------------------------------------\n",
      "[44, 12, 45, 46, 9, 17]\n",
      "--------------------------------------------------\n",
      "[44, 12]\n",
      "[44, 12, 45]\n",
      "[44, 12, 45, 46]\n",
      "[44, 12, 45, 46, 9]\n",
      "[44, 12, 45, 46, 9, 17]\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    print('--'*25)\n",
    "    print(token_list)\n",
    "    print('--'*25)\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        print(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token_list):\n",
    "  ng = []\n",
    "  for i in range(1, len(token_list)):\n",
    "    n_gram_sequence = token_list[:i+1]\n",
    "    ng.append(n_gram_sequence)\n",
    "  return ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Moon in both [houses]...\"...Scorpio, [Arabian Skies], Libra...\"...Pluto was not discovered until 1930...\"\\nLime and limpid green, a second scene\\nA fight between the blue you once knew\\nFloating down, the sound resounds\\nAround the icy waters underground\\nJupiter and Saturn, Oberon, Miranda and Titania\\nNeptune, Titan, stars can frighten\\n\\nBlinding signs flap\\nFlicker, flicker, flicker, blam\\nPow, pow\\nStairway scare Dan Dare who’s there?\\n\\nLime and limpid green, the sound surrounds\\nThe icy waters under\\nLime and limpid green, the sound surrounds\\nThe icy waters underground'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0]].lyrics.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqform(data):\n",
    "  tokenise = Tokenizer()\n",
    "  input_sequences = []\n",
    "  corpus = []\n",
    "  k=0\n",
    "  for i in range(0,len(df)):\n",
    "      text = df.iloc[[i]].lyrics.iloc[0]\n",
    "      if type(text)==float:\n",
    "          pass\n",
    "      else:\n",
    "          text = text.lower().split(\"\\n\")\n",
    "          text = [re.sub(r'\\d+', '', i) for i in text]\n",
    "          text = list(set(text))\n",
    "          if text==' ':\n",
    "              pass\n",
    "          else:\n",
    "              corpus.extend(text)\n",
    "              k+=1\n",
    "  tokenise.fit_on_texts(corpus)\n",
    "  for line in corpus:\n",
    "      token_list = tokenise.texts_to_sequences([line])[0]\n",
    "      input_sequences.extend(ngram(token_list))\n",
    " \n",
    "  \n",
    "  max_sequence_len = max([len(x) for x in input_sequences])\n",
    "  input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                       maxlen = max_sequence_len, padding='pre'))\n",
    "  \n",
    "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "  fin_data = pd.DataFrame(np.hstack((predictors, label.reshape(-1,1))),columns=np.hstack((np.arange(1,predictors.shape[1]+1),np.array(['label']))))\n",
    "  total_words = len(tokenise.word_index) + 1\n",
    "  print('{} number of lyrics inputted'.format(k))\n",
    "\n",
    "  return fin_data,tokenise,max_sequence_len,total_words,predictors,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 number of lyrics inputted\n",
      "(13839, 88) 88 2983\n"
     ]
    }
   ],
   "source": [
    "fdf,tokenise,max_sequence_len,total_words,predictors,label = seqform(df)\n",
    "print(fdf.shape,max_sequence_len,total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf .to_csv('fin_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13839\n",
      "13839\n"
     ]
    }
   ],
   "source": [
    "dataX = [fdf.iloc[i,0:87].tolist() for i in range(0,fdf.shape[0])]\n",
    "dataY = [fdf.iloc[i,87] for i in range(0,fdf.shape[0])]\n",
    "print(len(dataX))\n",
    "print(len(dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (13839, 87, 1))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 16:05:43.698388: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 87, 150)           447450    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 87, 300)          361200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 87, 300)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1491)              150591    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2983)              4450636   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,570,277\n",
      "Trainable params: 5,570,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 150, input_length=max_sequence_len-1))\n",
    "# Add an LSTM Layer\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))  \n",
    "# A dropout layer for regularisation\n",
    "model.add(Dropout(0.2))\n",
    "# Add another LSTM Layer\n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(total_words/2, activation='relu'))  \n",
    "# In the last layer, the shape should be equal to the total number of words present in our corpus\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 6.5786 - accuracy: 0.0655\n",
      "Epoch 00001: loss improved from inf to 6.57862, saving model to weights-improvement-01-6.5786.hdf5\n",
      "433/433 [==============================] - 212s 467ms/step - loss: 6.5786 - accuracy: 0.0655\n",
      "Epoch 2/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 6.0848 - accuracy: 0.0754\n",
      "Epoch 00002: loss improved from 6.57862 to 6.08481, saving model to weights-improvement-02-6.0848.hdf5\n",
      "433/433 [==============================] - 202s 466ms/step - loss: 6.0848 - accuracy: 0.0754\n",
      "Epoch 3/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.8482 - accuracy: 0.0765\n",
      "Epoch 00003: loss improved from 6.08481 to 5.84820, saving model to weights-improvement-03-5.8482.hdf5\n",
      "433/433 [==============================] - 177s 409ms/step - loss: 5.8482 - accuracy: 0.0765\n",
      "Epoch 4/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.6129 - accuracy: 0.0842\n",
      "Epoch 00004: loss improved from 5.84820 to 5.61286, saving model to weights-improvement-04-5.6129.hdf5\n",
      "433/433 [==============================] - 167s 384ms/step - loss: 5.6129 - accuracy: 0.0842\n",
      "Epoch 5/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.3838 - accuracy: 0.0951\n",
      "Epoch 00005: loss improved from 5.61286 to 5.38381, saving model to weights-improvement-05-5.3838.hdf5\n",
      "433/433 [==============================] - 166s 383ms/step - loss: 5.3838 - accuracy: 0.0951\n",
      "Epoch 6/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.1747 - accuracy: 0.1101\n",
      "Epoch 00006: loss improved from 5.38381 to 5.17467, saving model to weights-improvement-06-5.1747.hdf5\n",
      "433/433 [==============================] - 168s 387ms/step - loss: 5.1747 - accuracy: 0.1101\n",
      "Epoch 7/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.9888 - accuracy: 0.1225\n",
      "Epoch 00007: loss improved from 5.17467 to 4.98878, saving model to weights-improvement-07-4.9888.hdf5\n",
      "433/433 [==============================] - 167s 385ms/step - loss: 4.9888 - accuracy: 0.1225\n",
      "Epoch 8/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.8054 - accuracy: 0.1395\n",
      "Epoch 00008: loss improved from 4.98878 to 4.80535, saving model to weights-improvement-08-4.8054.hdf5\n",
      "433/433 [==============================] - 192s 442ms/step - loss: 4.8054 - accuracy: 0.1395\n",
      "Epoch 9/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.6296 - accuracy: 0.1517\n",
      "Epoch 00009: loss improved from 4.80535 to 4.62959, saving model to weights-improvement-09-4.6296.hdf5\n",
      "433/433 [==============================] - 177s 408ms/step - loss: 4.6296 - accuracy: 0.1517\n",
      "Epoch 10/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.4477 - accuracy: 0.1628\n",
      "Epoch 00010: loss improved from 4.62959 to 4.44774, saving model to weights-improvement-10-4.4477.hdf5\n",
      "433/433 [==============================] - 187s 432ms/step - loss: 4.4477 - accuracy: 0.1628\n",
      "Epoch 11/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.2864 - accuracy: 0.1721\n",
      "Epoch 00011: loss improved from 4.44774 to 4.28644, saving model to weights-improvement-11-4.2864.hdf5\n",
      "433/433 [==============================] - 165s 382ms/step - loss: 4.2864 - accuracy: 0.1721\n",
      "Epoch 12/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.1154 - accuracy: 0.1836\n",
      "Epoch 00012: loss improved from 4.28644 to 4.11541, saving model to weights-improvement-12-4.1154.hdf5\n",
      "433/433 [==============================] - 172s 398ms/step - loss: 4.1154 - accuracy: 0.1836\n",
      "Epoch 13/60\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.9563 - accuracy: 0.1960\n",
      "Epoch 00013: loss improved from 4.11541 to 3.95629, saving model to weights-improvement-13-3.9563.hdf5\n",
      "433/433 [==============================] - 169s 391ms/step - loss: 3.9563 - accuracy: 0.1960\n",
      "Epoch 14/60\n",
      "275/433 [==================>...........] - ETA: 1:04 - loss: 3.7829 - accuracy: 0.2045"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/86/b58mx9y52mq_z0wkgsjtgjqh0000gn/T/ipykernel_13845/662659942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X,y, epochs= 60,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-50-0.8289.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics='accuracy')\n",
    "model.fit(X, y, epochs=20, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac30f726a3612e8f542ca1e95ba0bd276dbd1b586db78f0bbd4db997dac7ff2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
