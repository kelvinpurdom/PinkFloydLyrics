{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5f096f",
   "metadata": {},
   "source": [
    "# Pink Floyd Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9e771-c4c8-4b2b-95b8-6b515bbf3960",
   "metadata": {},
   "source": [
    "##### The goal of the project is to analyse all Pink Floyd lyrics, and then build a model that can return a new song based on user input of 2 key words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2b610-a972-472d-a4ed-4a2209749fe3",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861f6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import array\n",
    "import sys\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499efff0-6b91-44d5-85aa-672b0adef8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openpyxl in /Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/Users/kelvinpurdom/.pyenv/versions/3.9.9/envs/lewagon/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81f18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../raw_data/pink_floyd_lyrics.csv\"\n",
    "df = pd.read_csv(file, decimal=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64269626-abe7-4e90-99ee-005baf05aa8a",
   "metadata": {},
   "source": [
    "### Formatting the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d39b7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song_title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Astronomy Domine</td>\n",
       "      <td>1967</td>\n",
       "      <td>\"Moon in both [houses]...\"...Scorpio, [Arabian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Lucifer Sam</td>\n",
       "      <td>1967</td>\n",
       "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Matilda Mother</td>\n",
       "      <td>1967</td>\n",
       "      <td>There was a king who ruled the land\\nHis Majes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Flaming</td>\n",
       "      <td>1967</td>\n",
       "      <td>Alone in the clouds all blue\\nLying on an eide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Pow R. Toc H.</td>\n",
       "      <td>1967</td>\n",
       "      <td>TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            album        song_title  year  \\\n",
       "0  The Piper at the Gates of Dawn  Astronomy Domine  1967   \n",
       "1  The Piper at the Gates of Dawn       Lucifer Sam  1967   \n",
       "2  The Piper at the Gates of Dawn    Matilda Mother  1967   \n",
       "3  The Piper at the Gates of Dawn           Flaming  1967   \n",
       "4  The Piper at the Gates of Dawn     Pow R. Toc H.  1967   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \"Moon in both [houses]...\"...Scorpio, [Arabian...  \n",
       "1  Lucifer Sam, siam cat\\nAlways sitting by your ...  \n",
       "2  There was a king who ruled the land\\nHis Majes...  \n",
       "3  Alone in the clouds all blue\\nLying on an eide...  \n",
       "4  TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e43e0d44-a21a-476b-9d0b-e6fb702c0e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song_title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Astronomy Domine</td>\n",
       "      <td>1967</td>\n",
       "      <td>\"Moon in both [houses]...\"...Scorpio, [Arabian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Lucifer Sam</td>\n",
       "      <td>1967</td>\n",
       "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Matilda Mother</td>\n",
       "      <td>1967</td>\n",
       "      <td>There was a king who ruled the land\\nHis Majes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Flaming</td>\n",
       "      <td>1967</td>\n",
       "      <td>Alone in the clouds all blue\\nLying on an eide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Pow R. Toc H.</td>\n",
       "      <td>1967</td>\n",
       "      <td>TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            album        song_title  year  \\\n",
       "0  The Piper at the Gates of Dawn  Astronomy Domine  1967   \n",
       "1  The Piper at the Gates of Dawn       Lucifer Sam  1967   \n",
       "2  The Piper at the Gates of Dawn    Matilda Mother  1967   \n",
       "3  The Piper at the Gates of Dawn           Flaming  1967   \n",
       "4  The Piper at the Gates of Dawn     Pow R. Toc H.  1967   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \"Moon in both [houses]...\"...Scorpio, [Arabian...  \n",
       "1  Lucifer Sam, siam cat\\nAlways sitting by your ...  \n",
       "2  There was a king who ruled the land\\nHis Majes...  \n",
       "3  Alone in the clouds all blue\\nLying on an eide...  \n",
       "4  TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['year'] = df['year'].apply(lambda x: (x.split('-')[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeea8e78-1802-41f8-8f5c-7d9770834f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12),edgecolor='blue')\n",
    "sns.countplot(x=\"year\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fee43b-19e3-4407-915e-03cea4a97630",
   "metadata": {},
   "source": [
    "### Start Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d68ba64a-5439-4aac-b92a-aca28a109fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'side': 1,\n",
       " 'that': 2,\n",
       " 'cat’s': 3,\n",
       " 'something': 4,\n",
       " 'i': 5,\n",
       " 'can’t': 6,\n",
       " 'explain': 7,\n",
       " 'cat': 8,\n",
       " 'you’re': 9,\n",
       " 'a': 10,\n",
       " 'the': 11,\n",
       " 'be': 12,\n",
       " 'lucifer': 13,\n",
       " 'always': 14,\n",
       " 'by': 15,\n",
       " 'your': 16,\n",
       " 'around': 17,\n",
       " 'sam': 18,\n",
       " 'siam': 19,\n",
       " 'sitting': 20,\n",
       " 'jennifer': 21,\n",
       " 'gentle': 22,\n",
       " 'witch': 23,\n",
       " 'left': 24,\n",
       " 'he’s': 25,\n",
       " 'right': 26,\n",
       " 'oh': 27,\n",
       " 'no': 28,\n",
       " 'go': 29,\n",
       " 'to': 30,\n",
       " 'sea': 31,\n",
       " 'hip': 32,\n",
       " 'ship’s': 33,\n",
       " 'somewhere': 34,\n",
       " 'anywhere': 35,\n",
       " 'at': 36,\n",
       " 'night': 37,\n",
       " 'prowling': 38,\n",
       " 'sifting': 39,\n",
       " 'sand': 40,\n",
       " 'hiding': 41,\n",
       " 'on': 42,\n",
       " 'ground': 43,\n",
       " 'he’ll': 44,\n",
       " 'found': 45,\n",
       " 'when': 46}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts([df.lyrics.iloc[1].replace('\\n',' \\n ')])\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0bdb38-dc68-4370-b956-dd6612bf7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.lyrics.iloc[1].split('\\n')\n",
    "text = [re.sub(r'\\d+', '', i) for i in text]\n",
    "corpus = list(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9415b33d-e2fc-4ccf-913d-5c92c952ca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Always sitting by your side',\n",
       " 'You’re the left side, he’s the right side',\n",
       " 'At night prowling, sifting sand',\n",
       " 'He’ll be found when you’re around',\n",
       " 'Be a hip cat, be a ship’s cat',\n",
       " 'Somewhere, anywhere',\n",
       " 'Lucifer, go to sea',\n",
       " 'Lucifer Sam, siam cat',\n",
       " 'That cat’s something I can’t explain',\n",
       " 'Jennifer Gentle, you’re a witch',\n",
       " 'Always by your side',\n",
       " 'Oh, no!',\n",
       " 'Hiding around on the ground']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "253c28c6-d070-4c3e-9b7a-f4e41527332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "[]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[14, 20, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[14, 20]\n",
      "[14, 20, 15]\n",
      "[14, 20, 15, 16]\n",
      "[14, 20, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[9, 11, 24, 1, 25, 11, 26, 1]\n",
      "--------------------------------------------------\n",
      "[9, 11]\n",
      "[9, 11, 24]\n",
      "[9, 11, 24, 1]\n",
      "[9, 11, 24, 1, 25]\n",
      "[9, 11, 24, 1, 25, 11]\n",
      "[9, 11, 24, 1, 25, 11, 26]\n",
      "[9, 11, 24, 1, 25, 11, 26, 1]\n",
      "--------------------------------------------------\n",
      "[36, 37, 38, 39, 40]\n",
      "--------------------------------------------------\n",
      "[36, 37]\n",
      "[36, 37, 38]\n",
      "[36, 37, 38, 39]\n",
      "[36, 37, 38, 39, 40]\n",
      "--------------------------------------------------\n",
      "[44, 12, 45, 46, 9, 17]\n",
      "--------------------------------------------------\n",
      "[44, 12]\n",
      "[44, 12, 45]\n",
      "[44, 12, 45, 46]\n",
      "[44, 12, 45, 46, 9]\n",
      "[44, 12, 45, 46, 9, 17]\n",
      "--------------------------------------------------\n",
      "[12, 10, 32, 8, 12, 10, 33, 8]\n",
      "--------------------------------------------------\n",
      "[12, 10]\n",
      "[12, 10, 32]\n",
      "[12, 10, 32, 8]\n",
      "[12, 10, 32, 8, 12]\n",
      "[12, 10, 32, 8, 12, 10]\n",
      "[12, 10, 32, 8, 12, 10, 33]\n",
      "[12, 10, 32, 8, 12, 10, 33, 8]\n",
      "--------------------------------------------------\n",
      "[34, 35]\n",
      "--------------------------------------------------\n",
      "[34, 35]\n",
      "--------------------------------------------------\n",
      "[13, 29, 30, 31]\n",
      "--------------------------------------------------\n",
      "[13, 29]\n",
      "[13, 29, 30]\n",
      "[13, 29, 30, 31]\n",
      "--------------------------------------------------\n",
      "[13, 18, 19, 8]\n",
      "--------------------------------------------------\n",
      "[13, 18]\n",
      "[13, 18, 19]\n",
      "[13, 18, 19, 8]\n",
      "--------------------------------------------------\n",
      "[2, 3, 4, 5, 6, 7]\n",
      "--------------------------------------------------\n",
      "[2, 3]\n",
      "[2, 3, 4]\n",
      "[2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[2, 3, 4, 5, 6, 7]\n",
      "--------------------------------------------------\n",
      "[21, 22, 9, 10, 23]\n",
      "--------------------------------------------------\n",
      "[21, 22]\n",
      "[21, 22, 9]\n",
      "[21, 22, 9, 10]\n",
      "[21, 22, 9, 10, 23]\n",
      "--------------------------------------------------\n",
      "[14, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[14, 15]\n",
      "[14, 15, 16]\n",
      "[14, 15, 16, 1]\n",
      "--------------------------------------------------\n",
      "[27, 28]\n",
      "--------------------------------------------------\n",
      "[27, 28]\n",
      "--------------------------------------------------\n",
      "[41, 17, 42, 11, 43]\n",
      "--------------------------------------------------\n",
      "[41, 17]\n",
      "[41, 17, 42]\n",
      "[41, 17, 42, 11]\n",
      "[41, 17, 42, 11, 43]\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    print('--'*25)\n",
    "    print(token_list)\n",
    "    print('--'*25)\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        print(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58d8b77-3745-446d-a89a-7c782575a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token_list):\n",
    "    ng = []\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        ng.append(n_gram_sequence)\n",
    "    return ng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c47d9e-f3b3-4b12-8a31-ae678908ba7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Moon in both [houses]...\"...Scorpio, [Arabian Skies], Libra...\"...Pluto was not discovered until 1930...\"\\nLime and limpid green, a second scene\\nA fight between the blue you once knew\\nFloating down, the sound resounds\\nAround the icy waters underground\\nJupiter and Saturn, Oberon, Miranda and Titania\\nNeptune, Titan, stars can frighten\\n\\nBlinding signs flap\\nFlicker, flicker, flicker, blam\\nPow, pow\\nStairway scare Dan Dare who’s there?\\n\\nLime and limpid green, the sound surrounds\\nThe icy waters under\\nLime and limpid green, the sound surrounds\\nThe icy waters underground'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0]].lyrics.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99b64d54-e7bf-4b1f-8286-f39c8e04d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29a29002-8678-4c65-b866-1d3b5642fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqform(data):\n",
    "  \n",
    "    tokenise = Tokenizer()\n",
    "    input_sequences = []\n",
    "    corpus = []\n",
    "    k=0\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "    \n",
    "        text = df.iloc[[i]].lyrics.iloc[0]\n",
    "        if type(text)==float:\n",
    "            pass\n",
    "        else:\n",
    "            text = text.lower().split(\"\\n\")\n",
    "            text = [re.sub(r'\\d+', '', i) for i in text]\n",
    "            text = list(set(text))\n",
    "            if text==' ':\n",
    "                pass\n",
    "            else:\n",
    "                corpus.extend(text)\n",
    "            k+=1\n",
    "            \n",
    "    tokenise.fit_on_texts(corpus)\n",
    "    for line in corpus:\n",
    "        token_list = tokenise.texts_to_sequences([line])[0]\n",
    "        input_sequences.extend(ngram(token_list))\n",
    " \n",
    "  \n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                       maxlen = max_sequence_len, padding='pre'))\n",
    "        \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    fin_data = pd.DataFrame(np.hstack((predictors, label.reshape(-1,1))),columns=np.hstack((np.arange(1,predictors.shape[1]+1),np.array(['label']))))\n",
    "    total_words = len(tokenise.word_index) + 1\n",
    "    print('{} number of lyrics inputted'.format(k))\n",
    "        \n",
    "    return fin_data,tokenise,max_sequence_len,total_words,predictors,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aca55a5-82d4-4981-9f52-89a4539249cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 number of lyrics inputted\n",
      "(13839, 88) 88 2983\n"
     ]
    }
   ],
   "source": [
    "fdf,tokenise,max_sequence_len,total_words,predictors,label = seqform(df)\n",
    "print(fdf.shape,max_sequence_len,total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc95ff31-5171-4b1e-ba94-f127b7ea1cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>296</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>296</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>834</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>834</td>\n",
       "      <td>633</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5  6  7  8  9  10  ...  79  80  81  82  83  84   85   86   87  \\\n",
       "0  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    0    1   \n",
       "1  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    1  356   \n",
       "2  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    1  356  296   \n",
       "3  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    0  513   \n",
       "4  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    0    1   \n",
       "5  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    1  356   \n",
       "6  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    1  356  296   \n",
       "7  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0    0  833   \n",
       "8  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0    0  833  834   \n",
       "9  0  0  0  0  0  0  0  0  0   0  ...   0   0   0   0   0   0  833  834  633   \n",
       "\n",
       "   label  \n",
       "0    356  \n",
       "1    296  \n",
       "2    512  \n",
       "3    513  \n",
       "4    356  \n",
       "5    296  \n",
       "6    260  \n",
       "7    834  \n",
       "8    633  \n",
       "9     33  \n",
       "\n",
       "[10 rows x 88 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc3607a0-0cd4-45c8-984c-59405c1c943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.to_csv('fin_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cd256-563c-4eaa-a43d-9f86a7c904fe",
   "metadata": {},
   "source": [
    "### Find Params for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d221413-6233-407f-8876-d2a7e502a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13839, 88)\n",
      "2982\n"
     ]
    }
   ],
   "source": [
    "print(fdf.shape)\n",
    "print(fdf.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99c4790c-d356-4957-ad73-b4758924c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13839\n",
      "13839\n"
     ]
    }
   ],
   "source": [
    "dataX = [fdf.iloc[i,0:87].tolist() for i in range(0,fdf.shape[0])]\n",
    "dataY = [fdf.iloc[i,87] for i in range(0,fdf.shape[0])]\n",
    "print(len(dataX))\n",
    "print(len(dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "621c0908-9a14-408a-b7d7-9bd94fbfae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (13839, 87, 1))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46f85b30-782b-429f-ad72-a7ccecaf2b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13839, 87)\n",
      "(13839,)\n",
      "(13839, 87, 1) (13839, 2981)\n",
      "2983 88\n"
     ]
    }
   ],
   "source": [
    "len(y[0])\n",
    "print(predictors.shape)\n",
    "print(label.shape)\n",
    "print(X.shape,y.shape)\n",
    "print(total_words,max_sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f2595-42f1-4108-a22e-c052228a55cd",
   "metadata": {},
   "source": [
    "### Designing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60c19d75-95f8-40cd-bfe4-df78f4fee55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 87, 150)           447450    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 87, 300)          361200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 87, 300)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1491)              150591    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2981)              4447652   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,567,293\n",
      "Trainable params: 5,567,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 150, input_length=max_sequence_len-1))\n",
    "# Add an LSTM Layer\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))  \n",
    "# A dropout layer for regularisation\n",
    "model.add(Dropout(0.2))\n",
    "# Add another LSTM Layer\n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(total_words/2, activation='relu'))  \n",
    "# In the last layer, the shape should be equal to the total number of words present in our corpus\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ec342b8-c458-45a9-b52d-9b0a020da4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "349b3f19-e42c-4508-b999-7cf90b838103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 6.5144 - accuracy: 0.0672\n",
      "Epoch 00001: loss improved from inf to 6.51442, saving model to weights-improvement-01-6.5144.hdf5\n",
      "433/433 [==============================] - 155s 358ms/step - loss: 6.5144 - accuracy: 0.0672\n",
      "Epoch 2/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 6.0757 - accuracy: 0.0751\n",
      "Epoch 00002: loss improved from 6.51442 to 6.07571, saving model to weights-improvement-02-6.0757.hdf5\n",
      "433/433 [==============================] - 152s 352ms/step - loss: 6.0757 - accuracy: 0.0751\n",
      "Epoch 3/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.8621 - accuracy: 0.0785\n",
      "Epoch 00003: loss improved from 6.07571 to 5.86209, saving model to weights-improvement-03-5.8621.hdf5\n",
      "433/433 [==============================] - 133s 308ms/step - loss: 5.8621 - accuracy: 0.0785\n",
      "Epoch 4/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.6269 - accuracy: 0.0864\n",
      "Epoch 00004: loss improved from 5.86209 to 5.62691, saving model to weights-improvement-04-5.6269.hdf5\n",
      "433/433 [==============================] - 134s 310ms/step - loss: 5.6269 - accuracy: 0.0864\n",
      "Epoch 5/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.4002 - accuracy: 0.0952\n",
      "Epoch 00005: loss improved from 5.62691 to 5.40023, saving model to weights-improvement-05-5.4002.hdf5\n",
      "433/433 [==============================] - 138s 318ms/step - loss: 5.4002 - accuracy: 0.0952\n",
      "Epoch 6/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.1967 - accuracy: 0.1084\n",
      "Epoch 00006: loss improved from 5.40023 to 5.19673, saving model to weights-improvement-06-5.1967.hdf5\n",
      "433/433 [==============================] - 141s 325ms/step - loss: 5.1967 - accuracy: 0.1084\n",
      "Epoch 7/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 5.0195 - accuracy: 0.1165\n",
      "Epoch 00007: loss improved from 5.19673 to 5.01948, saving model to weights-improvement-07-5.0195.hdf5\n",
      "433/433 [==============================] - 141s 327ms/step - loss: 5.0195 - accuracy: 0.1165\n",
      "Epoch 8/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.8536 - accuracy: 0.1275\n",
      "Epoch 00008: loss improved from 5.01948 to 4.85357, saving model to weights-improvement-08-4.8536.hdf5\n",
      "433/433 [==============================] - 149s 343ms/step - loss: 4.8536 - accuracy: 0.1275\n",
      "Epoch 9/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.6845 - accuracy: 0.1418\n",
      "Epoch 00009: loss improved from 4.85357 to 4.68450, saving model to weights-improvement-09-4.6845.hdf5\n",
      "433/433 [==============================] - 170s 392ms/step - loss: 4.6845 - accuracy: 0.1418\n",
      "Epoch 10/10\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.5234 - accuracy: 0.1504\n",
      "Epoch 00010: loss improved from 4.68450 to 4.52336, saving model to weights-improvement-10-4.5234.hdf5\n",
      "433/433 [==============================] - 143s 330ms/step - loss: 4.5234 - accuracy: 0.1504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ed0e670>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs= 10,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049da10f-e7bb-4b51-b5a6-2501dc1a1286",
   "metadata": {},
   "source": [
    "### Training the Model on improved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b937de1-d0fd-4bde-89d6-b90275f521fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.5760 - accuracy: 0.1633\n",
      "Epoch 00001: loss did not improve from 4.52336\n",
      "433/433 [==============================] - 145s 323ms/step - loss: 4.5760 - accuracy: 0.1633\n",
      "Epoch 2/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.2904 - accuracy: 0.1754\n",
      "Epoch 00002: loss improved from 4.52336 to 4.29039, saving model to weights-improvement-02-4.2904.hdf5\n",
      "433/433 [==============================] - 139s 320ms/step - loss: 4.2904 - accuracy: 0.1754\n",
      "Epoch 3/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 4.1049 - accuracy: 0.1882\n",
      "Epoch 00003: loss improved from 4.29039 to 4.10493, saving model to weights-improvement-03-4.1049.hdf5\n",
      "433/433 [==============================] - 139s 321ms/step - loss: 4.1049 - accuracy: 0.1882\n",
      "Epoch 4/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.9285 - accuracy: 0.1979\n",
      "Epoch 00004: loss improved from 4.10493 to 3.92851, saving model to weights-improvement-04-3.9285.hdf5\n",
      "433/433 [==============================] - 138s 320ms/step - loss: 3.9285 - accuracy: 0.1979\n",
      "Epoch 5/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.7627 - accuracy: 0.2114\n",
      "Epoch 00005: loss improved from 3.92851 to 3.76265, saving model to weights-improvement-05-3.7627.hdf5\n",
      "433/433 [==============================] - 144s 333ms/step - loss: 3.7627 - accuracy: 0.2114\n",
      "Epoch 6/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.5895 - accuracy: 0.2235\n",
      "Epoch 00006: loss improved from 3.76265 to 3.58951, saving model to weights-improvement-06-3.5895.hdf5\n",
      "433/433 [==============================] - 144s 332ms/step - loss: 3.5895 - accuracy: 0.2235\n",
      "Epoch 7/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.4425 - accuracy: 0.2422\n",
      "Epoch 00007: loss improved from 3.58951 to 3.44251, saving model to weights-improvement-07-3.4425.hdf5\n",
      "433/433 [==============================] - 162s 375ms/step - loss: 3.4425 - accuracy: 0.2422\n",
      "Epoch 8/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.3913 - accuracy: 0.2408\n",
      "Epoch 00008: loss improved from 3.44251 to 3.39130, saving model to weights-improvement-08-3.3913.hdf5\n",
      "433/433 [==============================] - 168s 388ms/step - loss: 3.3913 - accuracy: 0.2408\n",
      "Epoch 9/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.1769 - accuracy: 0.2704\n",
      "Epoch 00009: loss improved from 3.39130 to 3.17690, saving model to weights-improvement-09-3.1769.hdf5\n",
      "433/433 [==============================] - 171s 395ms/step - loss: 3.1769 - accuracy: 0.2704\n",
      "Epoch 10/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 3.0239 - accuracy: 0.2986\n",
      "Epoch 00010: loss improved from 3.17690 to 3.02386, saving model to weights-improvement-10-3.0239.hdf5\n",
      "433/433 [==============================] - 167s 385ms/step - loss: 3.0239 - accuracy: 0.2986\n",
      "Epoch 11/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.8877 - accuracy: 0.3171\n",
      "Epoch 00011: loss improved from 3.02386 to 2.88775, saving model to weights-improvement-11-2.8877.hdf5\n",
      "433/433 [==============================] - 177s 409ms/step - loss: 2.8877 - accuracy: 0.3171\n",
      "Epoch 12/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.7550 - accuracy: 0.3382\n",
      "Epoch 00012: loss improved from 2.88775 to 2.75502, saving model to weights-improvement-12-2.7550.hdf5\n",
      "433/433 [==============================] - 170s 392ms/step - loss: 2.7550 - accuracy: 0.3382\n",
      "Epoch 13/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.6281 - accuracy: 0.3610\n",
      "Epoch 00013: loss improved from 2.75502 to 2.62810, saving model to weights-improvement-13-2.6281.hdf5\n",
      "433/433 [==============================] - 166s 384ms/step - loss: 2.6281 - accuracy: 0.3610\n",
      "Epoch 14/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.5252 - accuracy: 0.3833\n",
      "Epoch 00014: loss improved from 2.62810 to 2.52518, saving model to weights-improvement-14-2.5252.hdf5\n",
      "433/433 [==============================] - 156s 360ms/step - loss: 2.5252 - accuracy: 0.3833\n",
      "Epoch 15/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.4106 - accuracy: 0.4066\n",
      "Epoch 00015: loss improved from 2.52518 to 2.41060, saving model to weights-improvement-15-2.4106.hdf5\n",
      "433/433 [==============================] - 161s 372ms/step - loss: 2.4106 - accuracy: 0.4066\n",
      "Epoch 16/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.3065 - accuracy: 0.4235\n",
      "Epoch 00016: loss improved from 2.41060 to 2.30648, saving model to weights-improvement-16-2.3065.hdf5\n",
      "433/433 [==============================] - 165s 381ms/step - loss: 2.3065 - accuracy: 0.4235\n",
      "Epoch 17/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.2087 - accuracy: 0.4446\n",
      "Epoch 00017: loss improved from 2.30648 to 2.20872, saving model to weights-improvement-17-2.2087.hdf5\n",
      "433/433 [==============================] - 166s 382ms/step - loss: 2.2087 - accuracy: 0.4446\n",
      "Epoch 18/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.1054 - accuracy: 0.4671\n",
      "Epoch 00018: loss improved from 2.20872 to 2.10540, saving model to weights-improvement-18-2.1054.hdf5\n",
      "433/433 [==============================] - 166s 384ms/step - loss: 2.1054 - accuracy: 0.4671\n",
      "Epoch 19/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 2.0375 - accuracy: 0.4823\n",
      "Epoch 00019: loss improved from 2.10540 to 2.03753, saving model to weights-improvement-19-2.0375.hdf5\n",
      "433/433 [==============================] - 166s 384ms/step - loss: 2.0375 - accuracy: 0.4823\n",
      "Epoch 20/20\n",
      "433/433 [==============================] - ETA: 0s - loss: 1.9448 - accuracy: 0.5030\n",
      "Epoch 00020: loss improved from 2.03753 to 1.94481, saving model to weights-improvement-20-1.9448.hdf5\n",
      "433/433 [==============================] - 164s 378ms/step - loss: 1.9448 - accuracy: 0.5030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ed4cd00>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"weights-improvement-10-4.5234.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics='accuracy')\n",
    "model.fit(X, y, epochs=20, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d39f642-a898-4825-a8e9-00e68ac347fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')\n",
    "model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "282d2ded-21a4-4ce9-8fe2-fc5e51375c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 15:12:23.946039: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x13ce8b190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x13c981d00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x13d38a6d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc772f-e80c-4b49-9d2a-5329a3a8906c",
   "metadata": {},
   "source": [
    "### Func to making lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65209066-f7b7-424d-b93e-b6676f97bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lyrics(seed_text, next_words):\n",
    "    pred_index=[]\n",
    "    for i in range(next_words):\n",
    "        token_list = tokenise.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list],\n",
    "                     maxlen=max_sequence_len-1,padding='pre')\n",
    "        #print(token_list.shape)\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len-1, 1))\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_index =  np.argmax(predicted)\n",
    "        pred_index.append(predicted_index)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenise.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    print(seed_text)\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2b698eb-370a-4873-8b0c-260ecb7cd45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "plans that either come to naught or\n"
     ]
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenise.word_index.items()))\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "pattern_val = [i for i in pattern if i>0]\n",
    "print(\"Seed:\")\n",
    "print(' '.join([reverse_word_map.get(value) for value in pattern_val]))\n",
    "seed_text = [reverse_word_map.get(value)+' ' for value in pattern_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0c02d-7fe0-4660-968f-b8179765d43d",
   "metadata": {},
   "source": [
    "### Playing with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56ffea41-0725-4bb8-a07d-12dc92150511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear else is no other in black ni incurable tyrants and kings to grow and high\n"
     ]
    }
   ],
   "source": [
    "line1 = make_lyrics('fear', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3d9bf-1daf-46ff-9d45-015da7f0b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
